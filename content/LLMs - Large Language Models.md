---
tags:
  - llm
  - ai
  - machine-learning
---
Large Language Models, or LLMs, are a specific type of [[Machine Learning]] model. They focus on performing natural language processing (NLP) tasks, taking as input text-based data and either categorizing the input text, or generating coherent, contextually-relevant output based on the input prompt. The function of such models is determined by whether they operate as a [[Discriminative AI]] or [[Generative AI]], and they serve as [[Foundational Models in Artificial Intelligence|foundational models]] for many other NLP models.

Furthermore, given that they focus on an interface that we as humans use every day - language - they have found their place as a go-to tool in modern-day society, serving as personal assistants, knowledge-sources and translators.
## Training
These models are trained on a vast array of text-based data from sources such as the Internet and books, to develop an understanding of the statistical relationships between words and phrases, semantics and structure of human languages.
## Examples
Some of the most commonly used LLM models today (06/12/2024) are:
- **GPT-4:** developed by OpenAI, and assumed to have approx. 1.76 trillion parameters. It is able to produce contextually-relevant responses to a vast array of input prompts.
- **GLaM:** developed by Google, and trained on Internet data. It therefore can produce responses on a variety of topics
- **BERT:** a relatively small LLM developed by Google, good at understanding natural language data and used in question-answering systems.
- **LLaMA (Large Language Model Meta AI):** developed by Meta using 20 different languages, and available for non-commercial use.